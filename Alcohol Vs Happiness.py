# -*- coding: utf-8 -*-
"""Zhang Final Code

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1g3UrhtC9MTB54pPCjpSyTiZexyr5XiFz
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

"""### **Data-Preprocessing**"""

from sklearn import preprocessing

min_max_scaler = preprocessing.MinMaxScaler()

"""### **Decision Tree**"""

alc = pd.read_csv('/content/drive/MyDrive/College/3Junior/S3/DSC 341/dataset.csv')
y = alc['Happy']
X = alc[['Beer_PerCapita', 'Spirit_PerCapita', 'Wine_PerCapita']]


alcName = ['Beer_PerCapita', 'Spirit_PerCapita', 'Wine_PerCapita']
alcName

"""Data split"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8, random_state=33)

X_train2, X_test2, y_val, y_val = train_test_split(X_train, y_train, test_size=0.8, random_state=33)

X_train_norm = min_max_scaler.fit_transform(X_train)
X_test_norm = min_max_scaler.fit_transform(X_test)

X_train2_norm = min_max_scaler.fit_transform(X_train2)
X_test2_norm = min_max_scaler.fit_transform(X_test2)

from sklearn import metrics

def measure_performance(X, y, clf, show_accuracy=True, show_classification_report=True, show_confussion_matrix=True):
    y_pred = clf.predict(X)
    if show_accuracy:
         print("Accuracy:{0:.3f}".format(metrics.accuracy_score(y, y_pred)),"\n")
    if show_classification_report:
        print("Classification report")
        print(metrics.classification_report(y, y_pred),"\n")

    if show_confussion_matrix:
        print("Confussion matrix")
        print(metrics.confusion_matrix(y, y_pred),"\n")

"""Accuracy of Decision Tree"""

from sklearn import tree
dt = tree.DecisionTreeClassifier(criterion='gini')
dt = dt.fit(X_train_norm, y_train)

from sklearn import metrics
measure_performance(X_test, y_test, dt, show_confussion_matrix=True, show_classification_report=False)

"""Accuracy of Random Forest"""

from sklearn.ensemble import RandomForestClassifier
rf = RandomForestClassifier(n_estimators=10, random_state=33)
rf = rf.fit(X_train_norm, y_train)

measure_performance(X_test, y_test, rf, show_confussion_matrix=False, show_classification_report=False)

"""Importance of features"""

from sklearn.model_selection import KFold

def calc_params(X, y, clf, param_values, param_name, K):

    # Convert input to Numpy arrays
    X = np.array(X)
    y = np.array(y)

    # initialize training and testing score arrays with zeros
    train_scores = np.zeros(len(param_values))
    test_scores = np.zeros(len(param_values))

    # iterate over the different parameter values
    for i, param_value in enumerate(param_values):

        # set classifier parameters
        clf.set_params(**{param_name:param_value})

        # initialize the K scores obtained for each fold
        k_train_scores = np.zeros(K)
        k_test_scores = np.zeros(K)

        # create KFold cross validation
        cv = KFold(n_splits=K, shuffle=True, random_state=0)

        # iterate over the K folds
        j = 0
        for train, test in cv.split(X):
            # fit the classifier in the corresponding fold
            # and obtain the corresponding accuracy scores on train and test sets
            clf.fit(X[train], y[train])
            k_train_scores[j] = clf.score(X[train], y[train])
            k_test_scores[j] = clf.score(X[test], y[test])
            j += 1

        # store the mean of the K fold scores
        train_scores[i] = np.mean(k_train_scores)
        test_scores[i] = np.mean(k_test_scores)
        print(param_name, '=', param_value, "Train =", train_scores[i], "Test =", test_scores[i])

    # plot the training and testing scores in a log scale
    plt.plot(param_values, train_scores, label='Train', alpha=0.4, lw=2, c='b')
    plt.plot(param_values, test_scores, label='X-Val', alpha=0.4, lw=2, c='g')
    plt.legend(loc=7)
    plt.xlabel(param_name + " values")
    plt.ylabel("Mean cross validation accuracy")

    # return the training and testing scores on each parameter value
    return train_scores, test_scores

msl = range(1,6)
print(msl)

rf = RandomForestClassifier(n_estimators=10, random_state=33)
train_scores, test_scores = calc_params(X_train_norm, y_train, rf, msl, 'min_samples_leaf', 5)

m_depth = [1,2,3,4,5,6, 7, 8]

rf = RandomForestClassifier(n_estimators=10, random_state=33)
train_scores, test_scores = calc_params(X_train_norm, y_train, rf, m_depth, 'max_depth', 5)

nest = range(5, 101, 5)
print(nest)

rf = RandomForestClassifier(n_estimators=10, random_state=33)
train_scores, test_scores = calc_params(X_train_norm, y_train, rf, nest, 'n_estimators', 5)

rf = RandomForestClassifier(n_estimators=20, min_samples_leaf=2, max_depth=4)
rf = rf.fit(X_train_norm, y_train)

measure_performance(X_test_norm, y_test, rf, show_confussion_matrix=True, show_classification_report=False)

"""## Tree"""

features = alcName
fig, ax = plt.subplots(figsize=(50,20))
tree.plot_tree(rf.estimators_[0], feature_names=features, class_names=["No","Yes"], filled=True, ax=ax);

"""### **KNN**"""

vs = alc.reindex(np.random.permutation(alc.index))
vs_target = vs.Happy

vs = pd.get_dummies(vs[['Beer_PerCapita', 'Spirit_PerCapita', 'Wine_PerCapita']])


tpercent = 0.8
tsize = int(tpercent * len(vs))
vs_train = vs[:tsize]
vs_test = vs[tsize:]

#validation + training of the first training
tsize2 = int(tpercent * len(vs_train))
vs_train2 = vs_train[:tsize2]
vs_val = vs_train[tsize2:]

vs_target_train = vs_target[0:int(tsize)]
vs_target_test = vs_target[int(tsize):len(vs)]

vs_target_trainval = vs_target[0:int(tsize2)]
vs_target_testval = vs_target[int(tsize2):len(vs_train)]

"""Data-Preprocessing"""

from sklearn import preprocessing

min_max_scaler = preprocessing.MinMaxScaler()
min_max_scaler.fit(vs_train)
min_max_scaler.fit(vs_train2)

vs_train_norm = min_max_scaler.fit_transform(vs_train)
vs_test_norm = min_max_scaler.fit_transform(vs_test)

vs_trainVal_norm = min_max_scaler.fit_transform(vs_train2)
vs_testVal_norm = min_max_scaler.fit_transform(vs_val)

np.set_printoptions(precision=2, linewidth=100)

vs_target_train = np.array(vs_target_train)
vs_target_test = np.array(vs_target_test)

vs_target_trainval = np.array(vs_target_trainval)
vs_target_testval = np.array(vs_target_testval)

from sklearn.metrics import confusion_matrix
from sklearn.neighbors import KNeighborsClassifier

knn = KNeighborsClassifier(n_neighbors=5, metric='euclidean')
knn.fit(vs_test_norm, vs_target_test)

knn.fit(vs_testVal_norm, vs_target_testval)

y_pred = knn.predict(vs_train_norm)

confusion_matrix(vs_target_train, y_pred)

y_pred_test = knn.predict(vs_test_norm)

confusion_matrix(vs_target_test, y_pred_test)

"""Validation Check"""

#Validation training
y_pred_val = knn.predict(vs_trainVal_norm)

confusion_matrix(vs_target_trainval, y_pred_val)

#validaion set
y_pred_valTest = knn.predict(vs_testVal_norm)

confusion_matrix(vs_target_testval, y_pred_valTest)

"""### **Clustering**"""

import matplotlib.pyplot as plt
from sklearn.cluster import KMeans

kmean = KMeans(n_clusters=2)
y_kmeans = kmean.fit_predict(X)

print(y_kmeans)

print(kmean.cluster_centers_)

Error = []
for i in range(1,11):
  kmeans = KMeans(n_clusters = i).fit(X)
  kmeans.fit(X)
  Error.append(kmeans.inertia_)

plt.plot(range(1,11), Error)
plt.title("Elbow")
plt.xlabel("Num Clusters")
plt.ylabel("Error")
plt.show()

